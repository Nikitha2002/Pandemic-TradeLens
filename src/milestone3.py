# -*- coding: utf-8 -*-
"""Milestone3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uqGQGk0nea3QlASaFbAvVSU8Nh8PAToA
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA


plt.rcParams.update({"figure.max_open_warning": 0})

DATA_PATH = "/content/final_trade_dataset.csv"
OUTPUT_DIR = "output_reports"
PLOTS_DIR = "plots"
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(PLOTS_DIR, exist_ok=True)

print("Setup complete.")

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('final_trade_dataset.csv')
df.head()

"""Dataset Loading"""

df = pd.read_csv(DATA_PATH)
print("Shape:", df.shape)
print("\nColumns:", df.columns.tolist())
display(df.head(10))
print("\nDtypes:\n", df.dtypes)

"""Missing Data Summary"""

missing_counts = df.isnull().sum()
missing_pct = 100 * missing_counts / len(df)
missing_summary = pd.DataFrame({
    "missing_count": missing_counts,
    "missing_pct": missing_pct
}).sort_values("missing_pct", ascending=False)

n_duplicates = int(df.duplicated().sum())

print("Number of rows:", len(df))
print("Number of duplicate rows:", n_duplicates)
display(missing_summary)

"""Handling missing Values"""

# - Drops exact duplicates, then normalizes string columns by trimming whitespace and converting empty strings to NaN so missingness is consistent.

# drop exact duplicates and report how many removed
before = len(df)
df = df.drop_duplicates(keep="first")
after = len(df)
print(f"Duplicates removed: {before - after}")

# Basic normalization of object/string columns
obj_cols = df.select_dtypes(include="object").columns.tolist()
for c in obj_cols:
    # strip leading/trailing whitespace and convert empty strings to NaN
    df[c] = df[c].astype(str).str.strip().replace({"": np.nan, "nan": np.nan})

# Recompute missing summary after these operations
missing_counts_after = df.isnull().sum()
missing_pct_after = 100 * missing_counts_after / len(df)
pd.DataFrame({"missing_count": missing_counts_after, "missing_pct": missing_pct_after}).sort_values("missing_pct", ascending=False).head(10)

"""Column Type Detection"""

def detect_column_types(df, cat_frac_threshold=0.05, cardinality_threshold=50):
    n = len(df)
    types = {}
    for col in df.columns:
        ser = df[col]

        if pd.api.types.is_datetime64_any_dtype(ser):
            types[col] = "datetime"
            continue

        if ser.dtype == "object":
            parsed = pd.to_datetime(ser, errors="coerce")
            if parsed.notnull().sum() / max(1, n) > 0.5:
                types[col] = "datetime"
                continue
        if pd.api.types.is_numeric_dtype(ser):
            unique_frac = ser.nunique(dropna=True) / max(1, n)
            if unique_frac <= cat_frac_threshold or ser.nunique() <= cardinality_threshold:
                types[col] = "categorical"
            else:
                types[col] = "numeric"
        elif pd.api.types.is_bool_dtype(ser):
            types[col] = "categorical"
        elif ser.dtype == "object":
            avg_len = ser.dropna().astype(str).str.len().mean() if ser.dropna().size else 0
            if ser.nunique(dropna=True) / max(1, n) <= cat_frac_threshold or ser.nunique() <= cardinality_threshold:
                types[col] = "categorical"
            elif avg_len > 100:
                types[col] = "text"
            else:
                types[col] = "categorical"
        else:
            types[col] = "other"
    return types

types = detect_column_types(df)
pd.Series(types, name="detected_type").to_csv(os.path.join(OUTPUT_DIR, "detected_column_types.csv"))
print("Detected column types (sample):")
display(pd.Series(types).head(50))

numeric_cols = [c for c, t in types.items() if t == "numeric"]
cat_cols = [c for c, t in types.items() if t == "categorical"]
datetime_cols = [c for c, t in types.items() if t == "datetime"]
text_cols = [c for c, t in types.items() if t == "text"]

print("\nNumeric columns:", numeric_cols)
print("Categorical columns:", cat_cols)
print("Datetime columns:", datetime_cols)
print("Text columns:", text_cols)

"""Missing Value Implementation:


For numeric: median imputation.

For categorical: most frequent (mode).
"""

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer, KNNImputer

# Use the df from earlier cells (assumes df exists)
working_df = df.copy()           # original (after duplicates removal & normalization)
print("Starting shape:", working_df.shape)

# 1) Normalize string-only "empty" values to actual NaN (strip whitespace)
obj_cols = working_df.select_dtypes(include="object").columns.tolist()
for c in obj_cols:

    working_df[c] = working_df[c].astype(object).where(~working_df[c].astype(str).str.strip().eq(""), np.nan)

# 2) Find columns that are 100% missing (all NaN)
all_missing_cols = [c for c in working_df.columns if working_df[c].isna().all()]
print(f"Columns with 100% missing values ({len(all_missing_cols)}):", all_missing_cols)

pd.Series(all_missing_cols, name="dropped_100pct_missing").to_csv(os.path.join(OUTPUT_DIR, "dropped_100pct_missing_columns.csv"), index=False)

# 3) Drop those columns
if all_missing_cols:
    working_df.drop(columns=all_missing_cols, inplace=True)
    print("Dropped columns with 100% missing values. New shape:", working_df.shape)
else:
    print("No fully-empty columns to drop.")

# 4) Re-detect numeric and categorical columns (after dropping)

def detect_numeric_and_categorical(df):
    numeric = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical = [c for c in df.columns if c not in numeric]
    return numeric, categorical

numeric_cols_post, cat_cols_post = detect_numeric_and_categorical(working_df)
print("\nNumeric columns (post-drop):", numeric_cols_post)
print("Categorical / other columns (post-drop):", cat_cols_post)

# 5) Impute numeric columns (median) if any exist
df_imputed = working_df.copy()
if numeric_cols_post:
    num_imp = SimpleImputer(strategy="median")
    df_imputed[numeric_cols_post] = num_imp.fit_transform(df_imputed[numeric_cols_post])
    print("Numeric columns imputed with median.")
else:
    print("No numeric columns to impute.")

# 6) Impute categorical columns (most_frequent) but skip any category columns that still have no observed values

cat_cols_to_impute = []
cat_cols_skipped = []
for c in cat_cols_post:
    # if there exists at least one non-null after previous operations -> impute it
    if df_imputed[c].notna().any():
        cat_cols_to_impute.append(c)
    else:
        cat_cols_skipped.append(c)

print(f"Categorical columns to impute: {len(cat_cols_to_impute)}; skipped (still empty): {len(cat_cols_skipped)}")
if cat_cols_skipped:
    print("Skipped categorical (no observed values):", cat_cols_skipped)

    pd.Series(cat_cols_skipped, name="skipped_empty_categorical_columns").to_csv(
        os.path.join(OUTPUT_DIR, "skipped_empty_categorical_columns.csv"), index=False
    )

if cat_cols_to_impute:
    cat_imp = SimpleImputer(strategy="most_frequent", fill_value="missing")
    df_imputed[cat_cols_to_impute] = cat_imp.fit_transform(df_imputed[cat_cols_to_impute])
    print("Categorical columns imputed with most frequent value.")
else:
    print("No categorical columns to impute.")

# 7) Save imputed dataset and print final shape
df_imputed.to_csv(os.path.join(OUTPUT_DIR, "cleaned_imputed_data.csv"), index=False)
print("Imputed dataset saved to", os.path.join(OUTPUT_DIR, "cleaned_imputed_data.csv"))
print("Final shape after imputation:", df_imputed.shape)

"""Outlier Detection
using two methods:
 1) IQR-based (commonly used)
 2) Z-score (statistical distance from mean
"""

def detect_outliers_iqr(df, cols, multiplier=1.5):
    out_idx = set()
    for c in cols:
        ser = df[c].dropna()
        q1 = ser.quantile(0.25)
        q3 = ser.quantile(0.75)
        iqr = q3 - q1
        lower = q1 - multiplier * iqr
        upper = q3 + multiplier * iqr
        idx = df[(df[c] < lower) | (df[c] > upper)].index
        out_idx.update(idx.tolist())
    return sorted(out_idx)

def detect_outliers_zscore(df, cols, z_thresh=3.0):
    out_idx = set()
    for c in cols:
        ser = df[c]
        if ser.dropna().empty:
            continue

        ser_numeric = pd.to_numeric(ser, errors='coerce').dropna()
        if ser_numeric.empty:
            continue
        z = np.abs(stats.zscore(ser_numeric))
        idx = ser_numeric.index[z > z_thresh]
        out_idx.update(idx.tolist())
    return sorted(out_idx)


outliers_iqr = detect_outliers_iqr(df_imputed, numeric_cols_post)
outliers_z = detect_outliers_zscore(df_imputed, numeric_cols_post)

print("IQR outlier count:", len(outliers_iqr))
print("Z-score outlier count:", len(outliers_z))


pd.DataFrame({"iqr_outlier_index": outliers_iqr}).to_csv(os.path.join(OUTPUT_DIR, "outliers_iqr.csv"), index=False)
pd.DataFrame({"z_outlier_index": outliers_z}).to_csv(os.path.join(OUTPUT_DIR, "outliers_zscore.csv"), index=False)
print("Outlier indices saved in output_reports/")


flagged_idx = sorted(set(outliers_iqr[:10] + outliers_z[:10]))
if flagged_idx:

    valid_flagged_idx = [idx for idx in flagged_idx if idx in df_imputed.index]
    if valid_flagged_idx:
        display(df_imputed.loc[valid_flagged_idx].head(10))
    else:
        print("No valid outlier indices to display.")
else:
    print("No outliers flagged by these methods (on numeric columns).")

"""Data type conversions & transformations

Converts any detected datetime columns to pandas datetime dtype.

For numeric columns with high positive skew (>1), applies log1p to reduce skewness.

Standardizes all numeric columns (zero mean, unit variance) and stores in a separate df.
"""

from sklearn.preprocessing import StandardScaler, MinMaxScaler
import numpy as np
import os


df_transformed = df_imputed.copy()


for c in datetime_cols:
    try:
        df_transformed[c] = pd.to_datetime(df_transformed[c], errors="coerce")
        print(f"Converted {c} to datetime.")
    except Exception as e:
        print(f"Failed to convert {c} to datetime: {e}")


skewed = []
for c in numeric_cols:
    if df_transformed[c].dropna().shape[0] < 5:
        continue
    sk = df_transformed[c].skew()
    if abs(sk) > 1:  # heuristic threshold

        if (df_transformed[c] >= -0.9).all():
            df_transformed[c + "_log1p"] = np.log1p(df_transformed[c])
            skewed.append(c)
        else:
            print(f"Skipping log transform for {c} due to negative values.")
print("Log-transformed columns:", skewed)


df_standardized = df_transformed.copy()
if numeric_cols:
    scaler_std = StandardScaler()
    df_standardized[numeric_cols] = scaler_std.fit_transform(df_transformed[numeric_cols])
    print("Standardized numeric columns (zero mean, unit variance).")
else:
    print("No numeric columns found for standardization.")


df_normalized = df_transformed.copy()
if numeric_cols:
    scaler_mm = MinMaxScaler()
    df_normalized[numeric_cols] = scaler_mm.fit_transform(df_transformed[numeric_cols])
    print("Min-Max normalization applied to numeric columns.")
else:
    print("No numeric columns found for normalization.")


df_transformed.to_csv(os.path.join(OUTPUT_DIR, "transformed_data.csv"), index=False)
df_standardized.to_csv(os.path.join(OUTPUT_DIR, "standardized_data.csv"), index=False)
df_normalized.to_csv(os.path.join(OUTPUT_DIR, "normalized_data.csv"), index=False)

print("\n✅ All transformed datasets saved:")
print(f"- Log+Base transformed: {os.path.join(OUTPUT_DIR, 'transformed_data.csv')}")
print(f"- Standardized:        {os.path.join(OUTPUT_DIR, 'standardized_data.csv')}")
print(f"- Normalized:          {os.path.join(OUTPUT_DIR, 'normalized_data.csv')}")

"""Summary Statistics


Computes descriptive statistics for numeric columns (mean, median, var, skew, kurtosis)and produces Pearson and Spearman correlation matrices and saves them.
"""

def summary_statistics(df, cols):
    s = pd.DataFrame(index=cols)
    s["count"] = df[cols].count()
    s["mean"] = df[cols].mean()
    s["median"] = df[cols].median()
    s["std"] = df[cols].std()
    s["var"] = df[cols].var()
    s["min"] = df[cols].min()
    s["max"] = df[cols].max()
    s["skew"] = df[cols].skew()
    s["kurtosis"] = df[cols].kurtosis()
    return s

if numeric_cols:
    stats_df = summary_statistics(df_imputed, numeric_cols)
    display(stats_df)
    stats_df.to_csv(os.path.join(OUTPUT_DIR, "numeric_summary_stats.csv"))
    print("Numeric summary saved.")

    if len(numeric_cols) >= 2:
        pearson = df_imputed[numeric_cols].corr(method="pearson")
        spearman = df_imputed[numeric_cols].corr(method="spearman")
        pearson.to_csv(os.path.join(OUTPUT_DIR, "pearson_corr.csv"))
        spearman.to_csv(os.path.join(OUTPUT_DIR, "spearman_corr.csv"))
        print("Correlation matrices saved.")
        display(pearson.head())
else:
    print("No numeric columns detected; skipping numeric summary.")

from scipy.stats import ks_2samp
import seaborn as sns

# Select a few key numeric indicators and countries for similarity analysis
selected_indicators_similarity = ['Exports (current US$)', 'Imports (current US$)', 'NY.GDP.MKTP.CD']
countries_for_similarity = ['USA', 'CHN', 'DEU', 'IND']

print("Performing data similarity analysis (Kolmogorov-Smirnov test) for selected indicators across countries:")

similarity_results = {}

for indicator in selected_indicators_similarity:
    similarity_results[indicator] = {}
    print(f"\nAnalyzing '{indicator}':")
    for i in range(len(countries_for_similarity)):
        for j in range(i + 1, len(countries_for_similarity)):
            country1 = countries_for_similarity[i]
            country2 = countries_for_similarity[j]

            data1 = df_imputed[(df_imputed['Country'] == country1)][indicator].dropna()
            data2 = df_imputed[(df_imputed['Country'] == country2)][indicator].dropna()

            if len(data1) > 0 and len(data2) > 0:
                # Perform Kolmogorov-Smirnov test
                ks_statistic, p_value = ks_2samp(data1, data2)

                similarity_results[indicator][f'{country1} vs {country2}'] = {'KS Statistic': ks_statistic, 'P-value': p_value}

                print(f"  {country1} vs {country2}: KS Statistic = {ks_statistic:.4f}, P-value = {p_value:.4f}")
            else:
                print(f"  Skipping {country1} vs {country2} for '{indicator}' due to insufficient data.")

print("\nVisualizing distributions for similarity comparison:")
for indicator in selected_indicators_similarity:
    plt.figure(figsize=(12, 6))
    for country in countries_for_similarity:
        sns.kdeplot(df_imputed[(df_imputed['Country'] == country)][indicator].dropna(), label=country, fill=True)
    plt.title(f'Distribution of {indicator} Across Selected Countries')
    plt.xlabel(indicator)
    plt.ylabel('Density')
    plt.legend()
    plt.show()

"""### Data Similarity Analysis

The code above performs a data similarity analysis by comparing the distributions of selected numeric indicators across a few chosen countries using the Kolmogorov-Smirnov (KS) test. The KS test assesses whether two samples are drawn from the same continuous distribution. A small p-value (typically < 0.05) suggests that the distributions are significantly different.

The visualizations (KDE plots) show the estimated probability density of the selected indicators for each country, allowing for a visual comparison of their distributions.

This analysis helps to understand how similar or different the economic characteristics (as represented by these indicators) are among the selected countries.

Data Quality Assesment

Compute completeness score, uniqueness per column **we need to give data ethics one para in this block**
"""

total_cells = df.size
total_missing = df.isnull().sum().sum()
completeness = 1 - (total_missing / total_cells)
uniqueness = df.nunique().sort_values(ascending=False)

print(f"Completeness score (0-1): {completeness:.4f}")
print("\nTop columns by unique values (possible IDs or high-cardinality):")
display(uniqueness.head(20))

import matplotlib.pyplot as plt
import seaborn as sns


numeric_cols_subset = ['Exports (current US$)', 'Imports (current US$)', 'NY.GDP.MKTP.CD', 'NE.EXP.GNFS.ZS']

print("Visualizing distributions of key numeric columns:")
for col in numeric_cols_subset:
    plt.figure(figsize=(10, 5))
    sns.histplot(df_imputed[col], kde=True)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()


categorical_cols_subset = ['Country', 'Source']

print("\nVisualizing counts of categorical columns:")
for col in categorical_cols_subset:
    plt.figure(figsize=(12, 6))
    df_imputed[col].value_counts().plot(kind='bar')
    plt.title(f'Count of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=90)
    plt.show()

"""## Data Quality Assesment: Completeness, Consistency, Usability

This section assesses the quality of the dataset focusing on completeness, consistency, usability, and check how it is relating with the research objectives from the data cleaning and exploration steps.

### Completeness

The final dataset consolidates information from three distinct sources — World Bank, IMF-style, and COVID Impact datasets — covering trade-related indicators such as exports, imports, and current account balances across multiple countries (2000–2023).

Coverage:

Temporal coverage: 2000–2023

Spatial coverage: ~260 countries and regions

Variables: exports, imports, current account balance, and trade values from different sources.

Missing Data:

Several entries contain missing values, particularly where data were not available from all three sources.

IMF-related columns (Exports, Imports, Current Account Balance) are often missing for countries or years that only appeared in the World Bank or COVID datasets.

Conversely, “Value” fields (from World Bank/COVID) are null for IMF records.

Conclusion: The dataset is comprehensive and reliable, covering over two decades and 260+ countries. It integrates World Bank, IMF, and COVID impact data, providing consistent and complete trade indicators for analyzing global trade dynamics and the effects of COVID-19.

### Consistency

Column Alignment: During cleaning, column names were standardized (Country, Year, Value, Exports (current US$), Imports (current US$), Current Account Balance (US$)), improving internal consistency.

Type Consistency:

The Year column was converted to integer values.

Monetary indicators were uniformly represented in current US$.

Duplication & Redundancy: Duplicates were dropped during preprocessing, ensuring one record per country-year-indicator combination.

Merged Source Integrity: Since three datasets were combined, each record was labeled by Source, preserving traceability of origin.

Conclusion: The dataset is internally consistent and harmonized, though cross-source differences (e.g., calculation methodologies between IMF and World Bank) may still introduce some variability.investigation.

### Usability

The dataset structure supports time series and cross-sectional analyses, making it suitable for:

Trend analysis (trade growth or decline)

Country comparisons

COVID-19 impact assessment (pre-, during-, and post-pandemic periods)

The standardized structure enables merging with additional indicators (e.g., GDP, population, or pandemic severity metrics) for deeper econometric modeling.

Some transformation (e.g., wide-to-long reshaping or normalization) may still be necessary depending on the analysis method.

Conclusion: The dataset is highly usable for the stated research objective: analyzing the global trade impact of COVID-19. individual features.

### Alignment with Research Objectives

This dataset aligns with research objectives because it covers trade indicators across pre-, during-, and post-COVID years (2015–2023) and it includes multiple metrics reflecting trade performance (exports, imports, total trade, and current account balances). Supports quantitative impact comparison across countries and time.

### Data Ethics, Bias, and Limitations

*   **Ethical Considerations:**

*   The dataset contains only aggregated, publicly available macroeconomic data — no personal, confidential, or identifiable information.

It adheres to ethical data use standards since all sources (World Bank, IMF, etc.) are transparent and reputable.

The data is used strictly for academic and analytical purposes, with no risk of harm, discrimination, or privacy violations.

Data Source Reliability:

Data originates from credible global organizations such as the World Bank, IMF-like databases, and COVID-related trade datasets.

Some differences in data collection and reporting methodologies may exist across these sources.

Bias and Representation:

Data gaps in developing or smaller economies may bias results toward larger economies with complete records.

The inclusion of regional aggregates (like AFE or AFW) could distort analysis if interpreted as individual countries.

Temporal Bias:

The COVID-19 period (2020–2021) may reflect delayed reporting or post-event data adjustments, affecting short-term accuracy.

Limitations:

Incomplete indicator coverage across all years and countries.

Variations in definitions of indicators (e.g., exports, imports) across institutions.

National-level scope limits insights into sectoral or firm-level trade impacts.

Conclusion:
The dataset is ethically sound, reliable, and suitable for academic research, though users should remain aware of coverage gaps and methodological differences when interpreting findings.
Reflecting on the data's ethical considerations, potential biases, and limitations is crucial for responsible and accurate analysis:

*   **Bias:**
    *   **Source Bias:** Data collected by international organizations like the IMF can be influenced by reporting capacities, methodologies, and priorities of member countries, leading to variations in data quality and availability.
    *   **Imputation Bias:** Simple imputation methods (median, mode) can distort the original data distribution and relationships between variables, potentially leading to biased estimates and conclusions.
    *   **Selection Bias:** The dataset includes a specific set of countries and years, which may not be representative of all global trade activities or historical periods, limiting the generalizability of findings. The exclusion of columns with 100% missing data is a form of data selection.
    *   **Indicator Bias:** The chosen indicators may not fully capture the complexity of international trade and economic development, potentially omitting crucial social, environmental, or political factors.
*   **Limitations:**
    *   **Missing Data:** Despite imputation, the substantial proportion of estimated values in some columns introduces uncertainty and may affect the reliability of analyses, especially those sensitive to precise values or distributions.
    *   **Outliers:** The presence of numerous outliers, if not appropriately handled, can disproportionately influence statistical measures and model results.
    *   **Data Granularity:** The data is annual and aggregated at the country level, which may not be sufficient for analyses requiring finer temporal or sub-national granularity.
    *   **Lack of Metadata:** Detailed information on the exact definitions, collection methodologies, and any revisions of the indicators is not immediately available within the dataset, making it harder to fully understand the data's context and potential limitations.
*   **Ethics:**
    *   **Responsible Interpretation:** Findings should be interpreted cautiously, acknowledging the data's limitations and potential biases, and avoiding overgeneralization or causal claims that are not fully supported.
    *   **Impact Awareness:** Researchers should consider the potential societal or economic impacts of their findings, particularly if they are used to inform policy or investment decisions.
    *   **Transparency:** Being transparent about the data sources, cleaning process, imputation methods, and any assumptions made during analysis is an ethical imperative.
    *   **Privacy and Confidentiality:** While this dataset appears to be aggregated public data, in general, researchers should be mindful of privacy and confidentiality when working with more granular or potentially identifiable trade or economic data.

By acknowledging these aspects, we can approach the analysis with greater rigor and responsibility.

###Advanced Data Understanding
Generated QQ plots for a subset of key numeric columns to assess normality visually.
"""

numeric_cols_subset_qq = ['Exports (current US$)', 'Imports (current US$)', 'NY.GDP.MKTP.CD', 'NY.GDP.MKTP.KD.ZG']

print("Generating QQ plots for key numeric columns:")


for col in numeric_cols_subset_qq:
    plt.figure(figsize=(8, 6))
    stats.probplot(df_transformed[col], dist="norm", plot=plt)
    plt.title(f'QQ Plot for {col}')
    plt.xlabel('Theoretical Quantiles')
    plt.ylabel('Sample Quantiles')
    plt.grid(True)
    plt.show()

"""
Performed visual diagnostics on the Pearson correlation matrix for the numeric columns to understand linear relationships.

"""

numeric_cols_corr = ['Exports (current US$)', 'Imports (current US$)', 'NY.GDP.MKTP.CD', 'NE.EXP.GNFS.ZS', 'NE.IMP.GNFS.ZS', 'NY.GDP.MKTP.KD.ZG', 'SH.XPD.CHEX.GD.ZS']

# Calculate Pearson correlation matrix
pearson_corr = df_imputed[numeric_cols_corr].corr(method='pearson')

# Create heatmap for Pearson correlation
plt.figure(figsize=(12, 10))
sns.heatmap(pearson_corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Pearson Correlation Heatmap of Selected Numeric Variables')
plt.show()

# Calculate Spearman correlation matrix
spearman_corr = df_imputed[numeric_cols_corr].corr(method='spearman')

# Create heatmap for Spearman correlation
plt.figure(figsize=(12, 10))
sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Spearman Correlation Heatmap of Selected Numeric Variables')
plt.show()

"""
Examined the `df_transformed` DataFrame and processed dataframes to confirm if it is the consolidated dataset for modeling. Then, final made report from the findings.

"""

print("Current state of df_transformed:")
display(df_transformed.head())
print("\nColumns in df_transformed:", df_transformed.columns.tolist())
print("\nData types in df_transformed:\n", df_transformed.dtypes)

print("\nOriginal columns:", df.columns.tolist())
print("\nNumeric columns after imputation:", [c for c in df_imputed.columns if pd.api.types.is_numeric_dtype(df_imputed[c])])
print("\nCategorical columns after imputation:", [c for c in df_imputed.columns if not pd.api.types.is_numeric_dtype(df_imputed[c])])
print("\nColumns in df_transformed:", df_transformed.columns.tolist())

"""
##Normalize and Transform
#### One-Hot Encoding of Categorical Variables

Applying one-hot encoding to the 'Country' and 'Source' categorical columns to convert them into a numerical format suitable for most machine learning algorithms."""

# Perform one-hot encoding on categorical columns
df_modeling = pd.get_dummies(df_transformed, columns=['Country', 'Source'], drop_first=True)

print("Shape after one-hot encoding:", df_modeling.shape)
print("\nColumns after one-hot encoding:", df_modeling.columns.tolist())
display(df_modeling.head())

"""###Visualizations
Generated histogram for a subset of numeric columns to visualize their distributions


"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

numeric_cols_subset_dist = ['Exports (current US$)', 'Imports (current US$)', 'NY.GDP.MKTP.CD', 'Current Account Balance (US$)']

print("Visualizing distributions of key numeric columns:")
for col in numeric_cols_subset_dist:
    plt.figure(figsize=(10, 5))
    # Use a larger number of bins for better detail
    sns.histplot(df_imputed[col], kde=True, bins=50)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()

    if df_imputed[col].min() > 0:
      plt.figure(figsize=(10, 5))
      sns.histplot(df_imputed[col], kde=True, bins=50)
      plt.xscale('log')
      plt.title(f'Distribution of {col} (Log Scale)')
      plt.xlabel(f'{col} (Log Scale)')
      plt.ylabel('Frequency')
      plt.show()


categorical_cols_subset = ['Country', 'Source']

print("\nVisualizing counts of categorical columns:")
for col in categorical_cols_subset:
    plt.figure(figsize=(12, 6))
    df_imputed[col].value_counts().plot(kind='bar')
    plt.title(f'Count of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=90)
    plt.show()

"""Description

we can see that the plots show Exports, Imports, and GDP which are heavily skewed towards lower values, with a few observations having significantly larger values, which is typically the economic data and the distribution Exports of percentage for GDP appears more spreaded.

Generate bubble chart which visualizes the relationship between Exports and Imports, with the size of each bubble representing the corresponding country's GDP for that year.
"""

plt.figure(figsize=(12, 8))

gdp_scaled = df_transformed['NY.GDP.MKTP.CD'] * 1000

scatter = sns.scatterplot(data=df_transformed, x='Exports (current US$)', y='Imports (current US$)', size=gdp_scaled, alpha=0.6, sizes=(20, 2000))

plt.title('Exports vs. Imports (Bubble size by GDP)')
plt.xlabel('Exports (current US$)')
plt.ylabel('Imports (current US$)')
plt.grid(True)
handles, labels = scatter.get_legend_handles_labels()
plt.legend(title='GDP (Scaled)', loc='upper left')

plt.show()

"""This plot shows a strong positive correlation between Exports, Imports, and GDP. where the larger bubbles (higher GDP) tend to be located in the upper right portion of the chart, showing that countries with larger economies generally have higher volumes of both exports and imports.

This pie chart shows the proportion of total exports contributed by a few of the top exporting countries in the latest year available in the dataset.
"""

# Find the latest year in the dataset
latest_year = df_imputed['Year'].max()
df_latest_year = df_imputed[df_imputed['Year'] == latest_year].copy()

# Group by country and sum exports, then select top N
top_countries_exports = df_latest_year.groupby('Country')['Exports (current US$)'].sum().sort_values(ascending=False).head(5)

# Add a category for 'Rest of World' for countries not in the top N
rest_of_world_exports = df_latest_year[~df_latest_year['Country'].isin(top_countries_exports.index)]['Exports (current US$)'].sum()
if rest_of_world_exports > 0:
    top_countries_exports['Rest of World'] = rest_of_world_exports

plt.figure(figsize=(10, 10))
plt.pie(top_countries_exports, labels=top_countries_exports.index, autopct='%1.1f%%', startangle=140)
plt.title(f'Distribution of Exports by Country in {int(latest_year)}')
plt.axis('equal')
plt.show()

"""The pie chart illustrates the concentration of global exports among a small no of countries, with remaining representing a significant portion. This highlights the dominance of major economies in international trade and suggests that analysis focusing solely on individual countries.

This area chart visualizes the trend of exports over time for a few selected countries, showing their contribution to the total exports over the years.

This waterfall chart visualizes the annual change in Exports for the USA over a selected period.
"""

import plotly.graph_objects as go
country = 'USA'
indicator = 'Exports (current US$)'
years_to_plot = range(2018, 2024)

df_waterfall = df_imputed[
    (df_imputed['Country'] == country) &
    (df_imputed['Year'].isin(years_to_plot))
].sort_values('Year').copy()

if not df_waterfall.empty:
    df_waterfall['Change'] = df_waterfall[indicator].diff().fillna(df_waterfall[indicator].iloc[0])
    data = []
    measures = ['absolute']
    x = [f'{int(df_waterfall["Year"].iloc[0])}']
    text = [f'{df_waterfall[indicator].iloc[0]:,.0f}']
    y = [df_waterfall[indicator].iloc[0]]
    increasing_color = 'green'
    decreasing_color = 'red'
    total_color = 'blue'


    for i in range(1, len(df_waterfall)):
        year = int(df_waterfall['Year'].iloc[i])
        change = df_waterfall['Change'].iloc[i]
        value = df_waterfall[indicator].iloc[i]

        measures.append('relative')
        x.append(f'{year}')
        text.append(f'{change:,.0f}')
        y.append(change)

    measures.append('absolute')
    x.append('Total')
    text.append(f'{df_waterfall[indicator].iloc[-1]:,.0f}')
    y.append(df_waterfall[indicator].iloc[-1])


    fig = go.Figure(go.Waterfall(
        name = country,
        orientation = "v",
        measure = measures,
        x = x,
        textposition = "outside",
        text = text,
        y = y,
        connector = {"line":{"color":"rgb(63, 63, 63)"}},
        increasing = {"marker":{"color": increasing_color}},
        decreasing = {"marker":{"color": decreasing_color}},
        totals = {"marker":{"color": total_color}},

    ))

    fig.update_layout(
            title = f"Waterfall Chart of {indicator} Change Over Time for {country}",
            showlegend = True
    )

    fig.show()

else:
    print(f"No data available for {country} in the selected years.")

"""This chart shows us the cumulative effect of yearly increases or decreases.
where we could see that it clearly shows there are fluctuations year by year in U.S. It also highlights specific years with increases or decreases by providing a granular view of export performance trends.
"""

selected_countries_area = ['USA', 'CHN', 'DEU', 'JPN'] # Example countries

df_area_chart = df_imputed[df_imputed['Country'].isin(selected_countries_area)].copy()

df_area_chart['Year'] = pd.to_numeric(df_area_chart['Year'])
df_area_chart = df_area_chart.sort_values('Year')

df_pivot = df_area_chart.pivot(index='Year', columns='Country', values='Exports (current US$)')
plt.figure(figsize=(14, 8))
df_pivot.plot(kind='area', stacked=True, alpha=0.7, ax=plt.gca()) # Use ax=plt.gca() to plot on the created figure
plt.title('Exports Over Time for Selected Countries')
plt.xlabel('Year')
plt.ylabel('Exports (current US$)')
plt.legend(title='Country')
plt.grid(True)
plt.show()

"""This area chart visualizes the trend of exports over time for a few selected countries which shows their contribution to the total exports over the years.

- It shows how the exports of selected major economies have evolved over time where the stacked areas illustrate the relative contribution of each country to the combined exports of the group and highlight their individual growth trajectories and periods of change.

generated a pair plot to visualize the relationships between them.
"""

numeric_cols_subset_relationships = ['Exports (current US$)', 'Imports (current US$)', 'NY.GDP.MKTP.CD', 'NE.EXP.GNFS.ZS', 'NE.IMP.GNFS.ZS']

print("Generating pair plot for key numeric relationships:")
sns.pairplot(df_imputed[numeric_cols_subset_relationships])
plt.suptitle('Pair Plot of Selected Numeric Variables', y=1.02)
plt.show()

"""It reveals strong positive linear relationships between the absolute value indicators (Exports, Imports, GDP) where it indicates that these variables tend to increase together.

Filterede the DataFrame for selected countries and economic indicators and then generated line plots for each country and indicator.
"""

# 1. Select few countries or regions
selected_countries = ['USA', 'CHN', 'DEU', 'BRA', 'IND']

# 2. Select a subset of key economic indicators
selected_indicators = ['Exports (current US$)', 'Imports (current US$)', 'NY.GDP.MKTP.CD']

# 3. Filter df_imputed for selected countries and indicators
df_filtered_time_series = df_imputed[df_imputed['Country'].isin(selected_countries)]

# 4. Iterate and create line plots
print("Generating time series plots for selected economic indicators in selected countries:")

for country in selected_countries:
    df_country = df_filtered_time_series[df_filtered_time_series['Country'] == country]
    if not df_country.empty:
        plt.figure(figsize=(14, 8))
        for indicator in selected_indicators:
            if indicator in df_country.columns:
                plt.plot(df_country['Year'], df_country[indicator], marker='o', linestyle='-', label=indicator)
        plt.title(f'Economic Indicators Over Time for {country}')
        plt.xlabel('Year')
        plt.ylabel('Value (current US$)')
        plt.legend()
        plt.grid(True)
        plt.show()
    else:
        print(f"No data available for {country} in the filtered DataFrame.")

"""These line plots show the trends of 'Exports (current US$)', 'Imports (current US$)', and 'NY.GDP.MKTP.CD' over time for selected countries (USA, CHN, DEU, BRA, IND).

the line plot illustrate the growth trajectories of these economies and the general increase in trade and GDP over the years with differences in scale and growth rates across countries where we can see China shows rapid growth.

created box plots to compare the distribution of these indicators across the selected countries.
"""

# Select a subset of key numeric indicators for comparison
selected_indicators_compare = ['Exports (current US$)', 'Imports (current US$)', 'NY.GDP.MKTP.CD']

# Select a reasonable number of countries for comparison
countries_to_compare = ['USA', 'CHN', 'JPN', 'DEU', 'IND', 'GBR', 'FRA', 'ITA', 'CAN', 'BRA']

# Filter the imputed dataframe to include only the selected countries
df_compare = df_imputed[df_imputed['Country'].isin(countries_to_compare)]

# Iterate through selected indicators and create box plots
print("Generating box plots to compare distributions across countries:")
for indicator in selected_indicators_compare:
    if indicator in df_compare.columns:
        plt.figure(figsize=(15, 8))
        sns.boxplot(x='Country', y=indicator, data=df_compare)
        plt.title(f'Distribution of {indicator} Across Selected Countries')
        plt.xlabel('Country')
        plt.ylabel(indicator)
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()
    else:
        print(f"Indicator '{indicator}' not found in the dataframe.")

"""The box plots compare the distribution of 'Exports (current US$)', 'Imports (current US$)', and 'NY.GDP.MKTP.CD' across a selection of countries.

- They clearly show the large disparities in economic scale across countries, with major economies exhibiting significantly higher median values and wider ranges for these indicators. we can also observe there are outliers in these plots which are consistent with the skewed distributions.

Calculated and visualized the Pearson and Spearman correlation matrices for the numeric columns to understand linear and non-linear relationships.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Select the numeric columns from the df_imputed DataFrame
numeric_cols_corr = [c for c in df_imputed.columns if pd.api.types.is_numeric_dtype(df_imputed[c])]

# Pearson correlation matrix
pearson_corr = df_imputed[numeric_cols_corr].corr(method='pearson')

# heatmap for Pearson correlation
plt.figure(figsize=(12, 10))
sns.heatmap(pearson_corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Pearson Correlation Heatmap of Numeric Variables')
plt.show()

# Spearman correlation matrix
spearman_corr = df_imputed[numeric_cols_corr].corr(method='spearman')

# heatmap for Spearman correlation
plt.figure(figsize=(12, 10))
sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Spearman Correlation Heatmap of Numeric Variables')
plt.show()

"""These heatmaps visualizes the Pearson (linear) and Spearman (rank-based) correlation matrices for the numeric columns.

- Both heatmaps show strong positive correlations between the absolute economic indicators (Exports, Imports, GDP), indicating that these variables tend to increase together. The Spearman correlations are slightly lower but still high. The correlations with percentage-based indicators and GDP growth rate are weaker.

Created bar plots for categorical variables to show the frequency of each category.
"""

# Select the categorical columns from the df_imputed DataFrame.
# Use the categorical columns detected earlier after imputation
categorical_cols_imputed = [c for c in df_imputed.columns if c in cat_cols_post]

print("\nVisualizing counts of categorical columns:")
# Iterate through the selected categorical columns.
for col in categorical_cols_imputed:
    plt.figure(figsize=(12, 6))
    sns.countplot(data=df_imputed, y=col, order=df_imputed[col].value_counts().index)
    plt.title(f'Count of {col}')
    plt.xlabel('Count')
    plt.ylabel(col)
    plt.tight_layout()
    plt.show()
    plt.close()

"""These bar plots show the frequency of each category in the Country and Source columns.

The Country plot shows that data is available for a large number of countries, with a relatively even distribution across most with some have more years of data than others. The Source    plot confirms that all data originates from the IMF.

Generated line plots comparing export and import values over time for specific countries or aggregated data.
"""

# 1. Select few countries
selected_countries_trade = ['USA', 'CHN', 'DEU', 'JPN', 'GBR'] # Selecting a few major economies

# 2. Filter the df_imputed DataFrame to include data for selected countries
df_filtered_countries = df_imputed[df_imputed['Country'].isin(selected_countries_trade)].copy()

df_filtered_countries['Year'] = pd.to_numeric(df_filtered_countries['Year'])

# 3. For each selected country, create a line plot
print("Generating line plots for Exports and Imports over time for selected countries:")

for country in selected_countries_trade:
    df_country_trade = df_filtered_countries[df_filtered_countries['Country'] == country]

    if not df_country_trade.empty:
        plt.figure(figsize=(12, 6))
        plt.plot(df_country_trade['Year'], df_country_trade['Exports (current US$)'], marker='o', linestyle='-', label='Exports (current US$)')
        plt.plot(df_country_trade['Year'], df_country_trade['Imports (current US$)'], marker='o', linestyle='-', label='Imports (current US$)')
        plt.title(f'Exports vs. Imports Over Time for {country}')
        plt.xlabel('Year')
        plt.ylabel('Value (current US$)')
        plt.legend()
        plt.grid(True)
        plt.show()
    else:
        print(f"No data available for {country} in the filtered DataFrame.")

"""These line plots compare the trends of 'Exports (current US$)' and 'Imports (current US$') over time for selected countries.

 The plot show that for most major economies, exports and imports tend to follow similar patterns and grow together over time. The gap between exports and imports indicates the trade balance for each country over the years.

Created a histogram with a KDE overlay for the GDP growth rate column to visualize its distribution.
"""

plt.figure(figsize=(10, 6))

sns.histplot(df_imputed['NY.GDP.MKTP.KD.ZG'], kde=True)
plt.title('Distribution of GDP Growth Rate')
plt.xlabel('GDP Growth Rate (%)')
plt.ylabel('Frequency')
plt.show()

"""This histogram with a Kernel Density Estimate (KDE) visualizes the distribution of the GDP growth rate (`NY.GDP.MKTP.KD.ZG`).

It shows that the growth rates are mostly centered around positive values, indicating overall economic expansion during the period covered by the dataset, but we can see there is a spread with instances of negative growth and higher growth spurts.

Visualized the trend of health expenditure over time by calculating the mean per year and plotting a line graph.
"""

health_expenditure_trend = df_imputed[['Year', 'SH.XPD.CHEX.GD.ZS']].groupby('Year')['SH.XPD.CHEX.GD.ZS'].mean().reset_index()
plt.figure(figsize=(12, 6))
plt.plot(health_expenditure_trend['Year'], health_expenditure_trend['SH.XPD.CHEX.GD.ZS'], marker='o', linestyle='-')
plt.title('Average Health Expenditure (% of GDP) Over Time')
plt.xlabel('Year')
plt.ylabel('Average Health Expenditure (% of GDP)')
plt.grid(True)
plt.show()
plt.close()

"""This line plot shows the trend of the average health expenditure as a percentage of GDP (`SH.XPD.CHEX.GD.ZS`) across all countries over time.

It suggests a general upward trend in health expenditure as a proportion of GDP over the years.

Generated a scatter plot to visualize the relationship between GDP (`NY.GDP.MKTP.CD`) and Exports (`Exports (current US$)`) across all countries and years in the dataset.
"""

plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_imputed, x='NY.GDP.MKTP.CD', y='Exports (current US$)')
plt.title('GDP vs. Exports (Current US$)')
plt.xlabel('GDP (current US$)')
plt.ylabel('Exports (current US$)')
plt.grid(True)
plt.show()

"""
This scatter plot visualizes the relationship between GDP (`NY.GDP.MKTP.CD`) and Exports (`Exports (current US$)`) across all countries and years in the dataset.

This plot shows a strong positive correlation between GDP and Exports. As GDP increases, Exports generally also increase. From this we can understand that larger economies tend to have higher export values."""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

numeric_cols_subset_dist = ['Exports (current US$)', 'Imports (current US$)', 'NY.GDP.MKTP.CD', 'Current Account Balance (US$)']

print("Visualizing distributions of key numeric columns:")
for col in numeric_cols_subset_dist:
    plt.figure(figsize=(10, 5))
    # Use a larger number of bins for better detail
    sns.histplot(df_imputed[col], kde=True, bins=50)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()

    if df_imputed[col].min() > 0:
      plt.figure(figsize=(10, 5))
      sns.histplot(df_imputed[col], kde=True, bins=50)
      plt.xscale('log')
      plt.title(f'Distribution of {col} (Log Scale)')
      plt.xlabel(f'{col} (Log Scale)')
      plt.ylabel('Frequency')
      plt.show()


categorical_cols_subset = ['Country', 'Source']

print("\nVisualizing counts of categorical columns:")
for col in categorical_cols_subset:
    plt.figure(figsize=(12, 6))
    df_imputed[col].value_counts().plot(kind='bar')
    plt.title(f'Count of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=90)
    plt.show()

!pip install mlxtend

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, classification_report,
                             mean_squared_error, r2_score, silhouette_score,
                             davies_bouldin_score)

from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression, Ridge

from mlxtend.frequent_patterns import apriori, association_rules

import warnings

warnings.filterwarnings("ignore", category=DeprecationWarning)

print("RAW-ish (after imputation, before encoding/scaling):")
display(df_imputed.head())

print("\nMODEL-READY (after one-hot encoding categorical columns):")
display(df_modeling.head())

"""#Frequent Pattern Mining

If a country has high exports and high GDP, then it is likely to have a positive current account balance.

"""

df_fp = df_imputed.copy()

# Define thresholds
exp_thresh = df_fp['Exports (current US$)'].quantile(0.75)
gdp_thresh = df_fp['NY.GDP.MKTP.CD'].quantile(0.75)
imp_thresh = df_fp['Imports (current US$)'].quantile(0.75)

df_fp['High_Exports'] = (df_fp['Exports (current US$)'] >= exp_thresh).astype(int)
df_fp['High_Imports'] = (df_fp['Imports (current US$)'] >= imp_thresh).astype(int)
df_fp['High_GDP']     = (df_fp['NY.GDP.MKTP.CD'] >= gdp_thresh).astype(int)

df_fp['Trade_Surplus'] = (df_fp['Current Account Balance (US$)'] > 0).astype(int)

# We'll keep just these binary indicators
fp_data = df_fp[['High_Exports','High_Imports','High_GDP','Trade_Surplus']]

print("Binarized data for association rule mining:")
display(fp_data.head())

# apriori expects booleans, not ints
fp_bool = fp_data.astype(bool)

frequent_itemsets = apriori(
    fp_bool,
    min_support=0.1,
    use_colnames=True
)

rules = association_rules(
    frequent_itemsets,
    metric="confidence",
    min_threshold=0.6  # tune this threshold
)

# Sort rules by lift so we see the most "interesting"
rules_sorted = rules.sort_values(by='lift', ascending=False)

print("Top association rules:")
display(rules_sorted.head(10))

"""The Apriori algorithm was chosen because the dataset was converted into binary indicators (High Exports, High Imports, High GDP), making it suitable for frequent pattern mining and discovering co-occurring economic behaviors during COVID. So, The model assumes boolean inputs and that frequent co-occurrence indicates meaningful associations (not causation). Hyperparameters such as min_support = 0.1 and confidence = 0.6 were tuned to balance rule quality and avoid noisy patterns. A challenge was that the original trade variables were continuous, so thresholds 75th percentile were used to binarize them. Another challenge was getting too many weak rules initially, which was resolved by adjusting the support/confidence values and sorting using lift to keep only strong, interpretable patterns.

## Regression Model
"""

# Regression Model Implementation

# Select features (X) and target (y)
# Using GDP to predict Exports as they showed a strong correlation
X = df_modeling[['NY.GDP.MKTP.CD']]
y = df_modeling['Exports (current US$)']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Linear Regression Model Performance:")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (R2): {r2:.2f}")

# Display model coefficients
print("\nModel Coefficients:")
print(f"Intercept: {model.intercept_:.2f}")
print(f"Coefficient for NY.GDP.MKTP.CD: {model.coef_[0]:.2f}")

# Plot actual vs predicted values for a subset
plt.figure(figsize=(10, 6))
plt.scatter(X_test['NY.GDP.MKTP.CD'][:100], y_test[:100], color='blue', label='Actual')
plt.scatter(X_test['NY.GDP.MKTP.CD'][:100], y_pred[:100], color='red', label='Predicted')
plt.title('Actual vs Predicted Exports (Subset)')
plt.xlabel('GDP (current US$)')
plt.ylabel('Exports (current US$)')
plt.legend()
plt.show()

df_reg = df_imputed.copy()

df_reg['log_gdp'] = np.log1p(df_reg['NY.GDP.MKTP.CD'])

X_reg = df_reg[['Exports (current US$)',
                'Imports (current US$)',
                'Current Account Balance (US$)']].fillna(0)
y_reg = df_reg['log_gdp']

Xr_train, Xr_test, yr_train, yr_test = train_test_split(
    X_reg, y_reg, test_size=0.2, random_state=42
)

# Scale predictors for stability (especially if we try Ridge)
scaler_reg = StandardScaler()
Xr_train_scaled = scaler_reg.fit_transform(Xr_train)
Xr_test_scaled  = scaler_reg.transform(Xr_test)

lin = LinearRegression()
lin.fit(Xr_train_scaled, yr_train)

ridge = Ridge()
param_grid_ridge = {'alpha': [0.1, 1.0, 10.0, 100.0]}
grid_ridge = GridSearchCV(ridge, param_grid_ridge, scoring='r2', cv=5, n_jobs=-1)
grid_ridge.fit(Xr_train_scaled, yr_train)

best_ridge = grid_ridge.best_estimator_
print("Best Ridge alpha:", grid_ridge.best_params_)

def evaluate_regressor(model, Xtr_s, Xte_s, ytr, yte, name="model"):
    model.fit(Xtr_s, ytr)
    y_pred = model.predict(Xte_s)

    mse  = mean_squared_error(yte, y_pred)
    rmse = np.sqrt(mse)
    r2   = r2_score(yte, y_pred)

    print(f"\n{name}")
    print("MSE :", mse)
    print("RMSE:", rmse)
    print("R²  :", r2)

evaluate_regressor(lin, Xr_train_scaled, Xr_test_scaled, yr_train, yr_test, "Linear Regression")
evaluate_regressor(best_ridge, Xr_train_scaled, Xr_test_scaled, yr_train, yr_test, "Ridge Regression")

"""The Linear Regression model was chosen because GDP and exports showed a strong positive correlation, making a linear model a good starting point for quantifying this relationship. The model assumes linearity, normally distributed errors, homoscedasticity, and no multicollinearity. For the multivariate setup, features were scaled and Ridge Regression was added to handle potential multicollinearity between exports, imports, and current account balance. Hyperparameter tuning (Ridge α = 0.1, 1, 10, 100) was performed using GridSearchCV to improve stability and reduce overfitting. A key challenge was the skewed GDP values, so log transformation was applied for better linear behavior, and scaling ensured model stability. Both models were evaluated using MSE, RMSE, and R² to compare performance.

##Classification Model
"""

df_classification = df_modeling.copy()

# Create binary label: Surplus (1) vs Deficit (0)
df_classification['Trade_Status'] = (
    df_imputed['Current Account Balance (US$)'] > 0
).astype(int)

# Drop columns you don't want as predictors.
# We'll drop direct leakage columns that basically *are* the answer,
# like the raw current account balance itself.
X = df_classification.drop(columns=['Trade_Status', 'Current Account Balance (US$)'], errors='ignore')
y = df_classification['Trade_Status']

print("X shape:", X.shape)
print("y value counts:\n", y.value_counts())

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled  = scaler.transform(X_test)

tree = DecisionTreeClassifier(class_weight='balanced', random_state=42)

param_grid_tree = {
    'max_depth': [3, 5, 7, 10, None],
    'min_samples_split': [2, 5, 10],
    'criterion': ['gini', 'entropy']
}

grid_tree = GridSearchCV(
    estimator=tree,
    param_grid=param_grid_tree,
    scoring='f1',        # optimize F1 for better balance
    cv=5,
    n_jobs=-1
)

grid_tree.fit(X_train, y_train)

best_tree = grid_tree.best_estimator_
print("Best Decision Tree params:", grid_tree.best_params_)

knn = KNeighborsClassifier()

param_grid_knn = {
    'n_neighbors': [3,5,7,9,11,15],
    'weights': ['uniform', 'distance']
}

grid_knn = GridSearchCV(
    estimator=knn,
    param_grid=param_grid_knn,
    scoring='f1',
    cv=5,
    n_jobs=-1
)

grid_knn.fit(X_train_scaled, y_train)

best_knn = grid_knn.best_estimator_
print("Best k-NN params:", grid_knn.best_params_)

def evaluate_classifier(model, Xtr, Xte, ytr, yte, model_name="model"):
    model.fit(Xtr, ytr)
    y_pred = model.predict(Xte)
    y_prob = None
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(Xte)[:,1]
    else:
        # some classifiers don't have predict_proba; skip ROC in that case
        y_prob = None

    print(f"\n=== {model_name} ===")
    print("Accuracy :", accuracy_score(yte, y_pred))
    print("Precision:", precision_score(yte, y_pred, zero_division=0))
    print("Recall   :", recall_score(yte, y_pred, zero_division=0))
    print("F1-score :", f1_score(yte, y_pred, zero_division=0))
    if y_prob is not None:
        print("ROC-AUC  :", roc_auc_score(yte, y_prob))

    print("\nClassification report:")
    print(classification_report(yte, y_pred, zero_division=0))


# Decision Tree on unscaled data
evaluate_classifier(
    best_tree, X_train, X_test, y_train, y_test, "Decision Tree"
)

# k-NN on scaled data
evaluate_classifier(
    best_knn, X_train_scaled, X_test_scaled, y_train, y_test, "k-NN"
)

"""The Decision Tree and k-NN models were chosen to classify countries into Trade Surplus vs. Deficit because the target is binary and both models work well with structured economic data. Decision Trees assume that data can be separated through hierarchical splits, while k-NN assumes that similar countries (in feature space) share similar trade outcomes. Hyperparameters for the Decision Tree (max_depth, min_samples_split, criterion) were tuned using GridSearchCV with F1-score to handle the class imbalance. For k-NN, scaling was applied because distance-based models are sensitive to feature magnitude. A key challenge was class imbalance (more deficit than surplus countries), so class_weight='balanced' and F1 optimization were used to improve recall. Both models were evaluated using accuracy, precision, recall, F1, and ROC-AUC.

#Clustering Model
"""

df_cluster = df_imputed.copy()

# avoid divide by zero
df_cluster = df_cluster.replace({0: np.nan})

df_cluster['exports_gdp'] = df_imputed['Exports (current US$)'] / df_imputed['NY.GDP.MKTP.CD']
df_cluster['imports_gdp'] = df_imputed['Imports (current US$)'] / df_imputed['NY.GDP.MKTP.CD']
df_cluster['cab_gdp']     = df_imputed['Current Account Balance (US$)'] / df_imputed['NY.GDP.MKTP.CD']
df_cluster['log_gdp']     = np.log1p(df_imputed['NY.GDP.MKTP.CD'])

cluster_features = df_cluster[['exports_gdp','imports_gdp','cab_gdp','log_gdp']].fillna(0)

scaler_cluster = StandardScaler()
X_cluster_scaled = scaler_cluster.fit_transform(cluster_features)

print("Clustering feature head:")
display(cluster_features.head())

results = []

for k in [2,3,4,5,6]:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X_cluster_scaled)

    sil = silhouette_score(X_cluster_scaled, labels)
    dbi = davies_bouldin_score(X_cluster_scaled, labels)

    results.append((k, sil, dbi))

results_df = pd.DataFrame(results, columns=['k','silhouette','davies_bouldin'])
print("K-Means evaluation over k:")
display(results_df)

best_k = results_df.sort_values(
    by=['silhouette','davies_bouldin'],
    ascending=[False, True]
).iloc[0]['k']

kmeans_final = KMeans(n_clusters=int(best_k), random_state=42, n_init=10)
cluster_labels = kmeans_final.fit_predict(X_cluster_scaled)

df_cluster['Cluster'] = cluster_labels

print(f"Chosen k = {best_k}")
display(df_cluster[['Country','Year','exports_gdp','imports_gdp','cab_gdp','log_gdp','Cluster']].head(20))

cluster_summary = df_cluster.groupby('Cluster')[['exports_gdp','imports_gdp','cab_gdp','log_gdp']].mean()
print("Cluster economic profiles (averages):")
display(cluster_summary)

"""K-Means clustering was chosen to explore natural groupings among countries based on trade indicators without using any labels. The model assumes that clusters are roughly spherical, features are continuous, and that points closer in feature space share similar economic characteristics. To improve performance, features were scaled using StandardScaler since K-Means is distance-based. The optimal number of clusters was selected using methods like the elbow curve or silhouette score. A challenge was that trade variables had different scales and skewness, so scaling and log transformations were applied to stabilize distances. The final clusters helped identify patterns such as high-GDP/high-trade countries versus low-trade or deficit-heavy economies.

# Performance Evaluation

```python
import numpy as np

print("--- Model Performance Evaluation ---")

# 1. Evaluate Classification Models
print("\n=== Classification Model Evaluation ===")
print("Decision Tree (best_tree):")
# Re-evaluate to print all metrics explicitly as per the plan, using the evaluate_classifier function.
# This assumes X_train, X_test, y_train, y_test, and best_tree are available from previous cells.
# For Decision Tree, unscaled data is used.
if 'best_tree' in locals() and 'X_train' in locals() and 'X_test' in locals() and 'y_train' in locals() and 'y_test' in locals():
    y_pred_tree = best_tree.predict(X_test)
    y_prob_tree = best_tree.predict_proba(X_test)[:, 1] if hasattr(best_tree, "predict_proba") else None
    print(f"  Accuracy : {accuracy_score(y_test, y_pred_tree):.4f}")
    print(f"  Precision: {precision_score(y_test, y_pred_tree, zero_division=0):.4f}")
    print(f"  Recall   : {recall_score(y_test, y_pred_tree, zero_division=0):.4f}")
    print(f"  F1-score : {f1_score(y_test, y_pred_tree, zero_division=0):.4f}")
    if y_prob_tree is not None:
        print(f"  ROC-AUC  : {roc_auc_score(y_test, y_prob_tree):.4f}")
else:
    print("  Classification metrics for Decision Tree could not be computed. Model or data not found.")

print("\nk-NN (best_knn):")
# For k-NN, scaled data (X_train_scaled, X_test_scaled) is used.
if 'best_knn' in locals() and 'X_train_scaled' in locals() and 'X_test_scaled' in locals() and 'y_train' in locals() and 'y_test' in locals():
    y_pred_knn = best_knn.predict(X_test_scaled)
    y_prob_knn = best_knn.predict_proba(X_test_scaled)[:, 1] if hasattr(best_knn, "predict_proba") else None
    print(f"  Accuracy : {accuracy_score(y_test, y_pred_knn):.4f}")
    print(f"  Precision: {precision_score(y_test, y_pred_knn, zero_division=0):.4f}")
    print(f"  Recall   : {recall_score(y_test, y_pred_knn, zero_division=0):.4f}")
    print(f"  F1-score : {f1_score(y_test, y_pred_knn, zero_division=0):.4f}")
    if y_prob_knn is not None:
        print(f"  ROC-AUC  : {roc_auc_score(y_test, y_prob_knn):.4f}")
else:
    print("  Classification metrics for k-NN could not be computed. Model or data not found.")

# 2. Evaluate Regression Models
print("\n=== Regression Model Evaluation ===")
# This assumes lin, best_ridge, Xr_train_scaled, Xr_test_scaled, yr_train, yr_test are available from previous cells.

# Linear Regression
if 'lin' in locals() and 'Xr_train_scaled' in locals() and 'Xr_test_scaled' in locals() and 'yr_train' in locals() and 'yr_test' in locals():
    lin.fit(Xr_train_scaled, yr_train)
    y_pred_lin = lin.predict(Xr_test_scaled)
    mse_lin = mean_squared_error(yr_test, y_pred_lin)
    rmse_lin = np.sqrt(mse_lin)
    r2_lin = r2_score(yr_test, y_pred_lin)
    print("Linear Regression (lin):")
    print(f"  Mean Squared Error (MSE) : {mse_lin:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse_lin:.4f}")
    print(f"  R-squared (R²) : {r2_lin:.4f}")
else:
    print("  Regression metrics for Linear Regression could not be computed. Model or data not found.")

# Ridge Regression
print("\nRidge Regression (best_ridge):")
if 'best_ridge' in locals() and 'Xr_train_scaled' in locals() and 'Xr_test_scaled' in locals() and 'yr_train' in locals() and 'yr_test' in locals():
    best_ridge.fit(Xr_train_scaled, yr_train)
    y_pred_ridge = best_ridge.predict(Xr_test_scaled)
    mse_ridge = mean_squared_error(yr_test, y_pred_ridge)
    rmse_ridge = np.sqrt(mse_ridge)
    r2_ridge = r2_score(yr_test, y_pred_ridge)
    print(f"  Mean Squared Error (MSE) : {mse_ridge:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse_ridge:.4f}")
    print(f"  R-squared (R²) : {r2_ridge:.4f}")
else:
    print("  Regression metrics for Ridge Regression could not be computed. Model or data not found.")

# 3. Evaluate Clustering Model
print("\n=== Clustering Model Evaluation ===")
if 'results_df' in locals() and 'best_k' in locals():
    print("K-Means evaluation for various 'k' values:")
    display(results_df)

    optimal_k_metrics = results_df[results_df['k'] == best_k]
    if not optimal_k_metrics.empty:
        print(f"\nMetrics for the optimal k = {int(best_k)}:")
        print(f"  Silhouette Score     : {optimal_k_metrics['silhouette'].values[0]:.4f}")
        print(f"  Davies-Bouldin Index : {optimal_k_metrics['davies_bouldin'].values[0]:.4f}")
    else:
        print(f"Metrics for optimal k={best_k} not found in results_df.")
else:
    print("  Clustering metrics could not be computed. results_df or best_k not found.")


# 4. Evaluate Frequent Pattern Mining
print("\n=== Frequent Pattern Mining Evaluation ===")
if 'rules_sorted' in locals():
    print("Top Association Rules (sorted by Lift):")
    display(rules_sorted[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))
else:
    print("  Frequent Pattern Mining rules could not be displayed. rules_sorted not found.")

print("\n--- All requested evaluation metrics have been generated and displayed. ---")

```

# Evaluation of Classification Models
"""

def evaluate_classifier(model, Xtr, Xte, ytr, yte, model_name="model"):
    model.fit(Xtr, ytr)
    y_pred = model.predict(Xte)
    y_prob = None
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(Xte)[:,1]
    else:
        # some classifiers don't have predict_proba; skip ROC in that case
        y_prob = None

    print(f"\n=== {model_name} ===")
    print("Accuracy :", accuracy_score(yte, y_pred))
    print("Precision:", precision_score(yte, y_pred, zero_division=0))
    print("Recall   :", recall_score(yte, y_pred, zero_division=0))
    print("F1-score :", f1_score(yte, y_pred, zero_division=0))
    if y_prob is not None:
        print("ROC-AUC  :", roc_auc_score(yte, y_prob))

    print("\nClassification report:")
    print(classification_report(yte, y_pred, zero_division=0))


# Decision Tree on unscaled data
evaluate_classifier(
    best_tree, X_train, X_test, y_train, y_test, "Decision Tree"
)

# k-NN on scaled data
evaluate_classifier(
    best_knn, X_train_scaled, X_test_scaled, y_train, y_test, "k-NN"
)

"""# Evaluation of Regression Models


"""

evaluate_regressor(lin, Xr_train_scaled, Xr_test_scaled, yr_train, yr_test, "Linear Regression")
evaluate_regressor(best_ridge, Xr_train_scaled, Xr_test_scaled, yr_train, yr_test, "Ridge Regression")

"""#Evaluation of Clustering Model


"""

print("K-Means evaluation for various 'k' values:")
display(results_df)

optimal_k_metrics = results_df[results_df['k'] == best_k]
if not optimal_k_metrics.empty:
    print(f"\nMetrics for the optimal k = {int(best_k)}:")
    print(f"  Silhouette Score     : {optimal_k_metrics['silhouette'].values[0]:.4f}")
    print(f"  Davies-Bouldin Index : {optimal_k_metrics['davies_bouldin'].values[0]:.4f}")
else:
    print(f"Metrics for optimal k={best_k} not found in results_df.")

"""## Compare Model Performances and Identify Best Approach


"""

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error, r2_score

print("--- Model Performance Evaluation ---")

# 1. Evaluate Classification Models
print("\n=== Classification Model Evaluation ===")
print("Decision Tree (best_tree):")
# Re-evaluate to print all metrics explicitly as per the plan, using the evaluate_classifier function.
# This assumes X_train, X_test, y_train, y_test, and best_tree are available from previous cells.
# For Decision Tree, unscaled data is used.
if 'best_tree' in locals() and 'X_train' in locals() and 'X_test' in locals() and 'y_train' in locals() and 'y_test' in locals():
    y_pred_tree = best_tree.predict(X_test)
    y_prob_tree = best_tree.predict_proba(X_test)[:, 1] if hasattr(best_tree, "predict_proba") else None
    print(f"  Accuracy : {accuracy_score(y_test, y_pred_tree):.4f}")
    print(f"  Precision: {precision_score(y_test, y_pred_tree, zero_division=0):.4f}")
    print(f"  Recall   : {recall_score(y_test, y_pred_tree, zero_division=0):.4f}")
    print(f"  F1-score : {f1_score(y_test, y_pred_tree, zero_division=0):.4f}")
    if y_prob_tree is not None:
        print(f"  ROC-AUC  : {roc_auc_score(y_test, y_prob_tree):.4f}")
else:
    print("  Classification metrics for Decision Tree could not be computed. Model or data not found.")

print("\nk-NN (best_knn):")
# For k-NN, scaled data (X_train_scaled, X_test_scaled) is used.
if 'best_knn' in locals() and 'X_train_scaled' in locals() and 'X_test_scaled' in locals() and 'y_train' in locals() and 'y_test' in locals():
    y_pred_knn = best_knn.predict(X_test_scaled)
    y_prob_knn = best_knn.predict_proba(X_test_scaled)[:, 1] if hasattr(best_knn, "predict_proba") else None
    print(f"  Accuracy : {accuracy_score(y_test, y_pred_knn):.4f}")
    print(f"  Precision: {precision_score(y_test, y_pred_knn, zero_division=0):.4f}")
    print(f"  Recall   : {recall_score(y_test, y_pred_knn, zero_division=0):.4f}")
    print(f"  F1-score : {f1_score(y_test, y_pred_knn, zero_division=0):.4f}")
    if y_prob_knn is not None:
        print(f"  ROC-AUC  : {roc_auc_score(y_test, y_prob_knn):.4f}")
else:
    print("  Classification metrics for k-NN could not be computed. Model or data not found.")

# 2. Evaluate Regression Models
print("\n=== Regression Model Evaluation ===")
# This assumes lin, best_ridge, Xr_train_scaled, Xr_test_scaled, yr_train, yr_test are available from previous cells.

# Linear Regression
if 'lin' in locals() and 'Xr_train_scaled' in locals() and 'Xr_test_scaled' in locals() and 'yr_train' in locals() and 'yr_test' in locals():
    lin.fit(Xr_train_scaled, yr_train)
    y_pred_lin = lin.predict(Xr_test_scaled)
    mse_lin = mean_squared_error(yr_test, y_pred_lin)
    rmse_lin = np.sqrt(mse_lin)
    r2_lin = r2_score(yr_test, y_pred_lin)
    print("Linear Regression (lin):")
    print(f"  Mean Squared Error (MSE) : {mse_lin:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse_lin:.4f}")
    print(f"  R-squared (R²) : {r2_lin:.4f}")
else:
    print("  Regression metrics for Linear Regression could not be computed. Model or data not found.")

# Ridge Regression
print("\nRidge Regression (best_ridge):")
if 'best_ridge' in locals() and 'Xr_train_scaled' in locals() and 'Xr_test_scaled' in locals() and 'yr_train' in locals() and 'yr_test' in locals():
    best_ridge.fit(Xr_train_scaled, yr_train)
    y_pred_ridge = best_ridge.predict(Xr_test_scaled)
    mse_ridge = mean_squared_error(yr_test, y_pred_ridge)
    rmse_ridge = np.sqrt(mse_ridge)
    r2_ridge = r2_score(yr_test, y_pred_ridge)
    print(f"  Mean Squared Error (MSE) : {mse_ridge:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {rmse_ridge:.4f}")
    print(f"  R-squared (R²) : {r2_ridge:.4f}")
else:
    print("  Regression metrics for Ridge Regression could not be computed. Model or data not found.")

# 3. Evaluate Clustering Model
print("\n=== Clustering Model Evaluation ===")
if 'results_df' in locals() and 'best_k' in locals():
    print("K-Means evaluation for various 'k' values:")
    display(results_df)

    optimal_k_metrics = results_df[results_df['k'] == best_k]
    if not optimal_k_metrics.empty:
        print(f"\nMetrics for the optimal k = {int(best_k)}:")
        print(f"  Silhouette Score     : {optimal_k_metrics['silhouette'].values[0]:.4f}")
        print(f"  Davies-Bouldin Index : {optimal_k_metrics['davies_bouldin'].values[0]:.4f}")
    else:
        print(f"Metrics for optimal k={best_k} not found in results_df.")
else:
    print("  Clustering metrics could not be computed. results_df or best_k not found.")


# 4. Evaluate Frequent Pattern Mining
print("\n=== Frequent Pattern Mining Evaluation ===")
if 'rules_sorted' in locals():
    print("Top Association Rules (sorted by Lift):")
    display(rules_sorted[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))
else:
    print("  Frequent Pattern Mining rules could not be displayed. rules_sorted not found.")

print("\n--- All requested evaluation metrics have been generated and displayed. ---")

"""#How each model has performed?

**Classification Models (Decision Tree vs. k-NN):**

k-NN was performed the best becuase it had a higher Accuracy (around 91% correct predictions) and was much better at correctly identifying both trade surpluses and deficits (shown by its stronger F1-score and ROC-AUC).
The Decision Tree was okay, but k-NN just made fewer mistakes and was more reliable for this task.

**Regression Models (Linear Regression vs. Ridge Regression):**

Both Linear Regression and Ridge Regression performed quite similarly, but neither was particularly great at predicting the log of GDP based on our chosen trade indicators.
Their R-squared values were low (around 0.24), meaning they only explained about 24% of the variations in log GDP. This suggests that these simple models, using only these specific inputs, aren't enough to accurately predict a country's economic size. We might need more data or different types of models for this.

**Clustering Model (K-Means):**

This model successfully grouped countries into two distinct categories based on their trade and economic characteristics. The high Silhouette Score (0.9429) and good Davies-Bouldin Index (0.6017) indicate that these two clusters are well-separated and meaningful.
It basically helped us see two main types of economic profiles among the countries in our dataset.

**Frequent Pattern Mining (Apriori Algorithm):**

This alogorithm is performed for finding common patterns and not for predicting where it shows strong relationships between high exports, high imports, and high GDP.
For example, if a country has high imports, it's very likely to also have high exports and a high GDP. This confirms our general understanding of how large economies tend to have a lot of trade.

##Which approach worked best?

The k-NN Classification Model stood out as the most effective since it was highly successful and reliable in predicting whether a country would have a trade surplus or deficit. From strong F1-score and ROC-AUC , it shows that it can confidently identify these economic conditions, which is a very practical and actionable insight for understanding country-level economic health. While other models provided valuable insights into relationships or groupings, k-NN delivered a clear, high-performing prediction.
"""

